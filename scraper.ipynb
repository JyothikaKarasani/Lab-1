{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "73cc9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url='https://cse.umn.edu/cs/faculty'\n",
    "page=requests.get(url)\n",
    "soup=BeautifulSoup(page.text,'html')\n",
    "\n",
    "\n",
    "faculty = soup.find_all('div',class_='pl-col-two')\n",
    "urls=[]\n",
    "for i in range(0,len(faculty)):\n",
    "    link=faculty[i].find_all('a')[0].get('href')\n",
    "    urls.append(link)\n",
    "    \n",
    "\n",
    "\n",
    "urls_file=open('bio_urls.txt','w')\n",
    "for link in urls:\n",
    "    print(\"https://cse.umn.edu\"+link+'\\n',file=urls_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dade2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "url='https://cse.umn.edu/cs/faculty'\n",
    "page=requests.get(url)\n",
    "soup=BeautifulSoup(page.text,'html')\n",
    "faculty = soup.find_all('div',class_='pl-col-two')\n",
    "\n",
    "\n",
    "urls=[]\n",
    "biography=[]\n",
    "for i in range(0,len(faculty)):\n",
    "    link=faculty[i].find_all('a')[0].get('href')\n",
    "    urls.append(link)\n",
    "    \n",
    "    \n",
    "Titles=[]\n",
    "for i in range(0,len(urls)):\n",
    "    url=\"https://cse.umn.edu\"+urls[i]\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.text,'html')\n",
    "    \n",
    "    \n",
    "    Titles.append((soup.find_all('h1'))[1].get_text())\n",
    "    \n",
    "    \n",
    "    number_of_sections=soup.find_all('section')\n",
    "    \n",
    "    \n",
    "    if len(number_of_sections)==0 :\n",
    "        biography.append('NO BIO FOUND')\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        bio_url=soup.find_all('section')[0]\n",
    "        p_tag=bio_url.find_all('p')\n",
    "        span_count=[]\n",
    "        \n",
    "        \n",
    "        if len(p_tag) <= 1 :\n",
    "            biography.append('NO BIO FOUND')\n",
    "            \n",
    "        elif len(p_tag) > 1 :\n",
    "            \n",
    "            for i in range(0,len(p_tag)):\n",
    "                span_tag=p_tag[i].find_all('span')\n",
    "                span_count.append(len(span_tag))\n",
    "                \n",
    "                \n",
    "        if len(span_count)==0:\n",
    "             biography.append('NO BIO FOUND')\n",
    "         \n",
    "        elif span_count[0]==span_count[1] :\n",
    "            \n",
    "            for j in range(0,len(p_tag)):\n",
    "                lengths=[]\n",
    "                lengths.append(len(p_tag[j].get_text()))\n",
    "                \n",
    "            biography.append(p_tag[lengths.index(max(lengths))].get_text())\n",
    "        \n",
    "    \n",
    "    \n",
    "        elif span_count[index]==0:\n",
    "            index=span_count.index(min(span_count))\n",
    "            biography.append(p_tag[index].get_text())\n",
    "        else:\n",
    "        \n",
    "            bio=p_tag[index].find_all('span')[0]\n",
    "            biography.append(bio.get_text())\n",
    "            \n",
    "    \n",
    "biography_file=open('bio.txt','w',encoding='utf-8')\n",
    "for i in range (0,70):\n",
    "        biography_file.write((Titles[i]+\": \"+biography[i] +\"\\n\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "96c51873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "url='https://cse.umn.edu/cs/faculty'\n",
    "page=requests.get(url)\n",
    "soup=BeautifulSoup(page.text,'html')\n",
    "faculty = soup.find_all('div',class_='pl-col-two')\n",
    "\n",
    "\n",
    "urls=[]\n",
    "biography=[]\n",
    "for i in range(0,len(faculty)):\n",
    "    link=faculty[i].find_all('a')[0].get('href')\n",
    "    urls.append(link)\n",
    "    \n",
    "    \n",
    "Titles=[]\n",
    "taught=[]\n",
    "for i in range(0,len(urls)):\n",
    "    url=\"https://cse.umn.edu\"+urls[i]\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.text,'html')\n",
    "    Titles.append((soup.find_all('h1'))[1].get_text())\n",
    "    \n",
    "    ul_tags=soup.find_all('ul',class_='person-teaching')\n",
    "    \n",
    "    if len(ul_tags)==0:\n",
    "        taught.append('doesnt take any classes')\n",
    "        \n",
    "        \n",
    "    if len(ul_tags)!=0:\n",
    "        course=[]\n",
    "        li_tags=ul_tags[0].find_all('li')\n",
    "        \n",
    "        for j in range(0,len(li_tags)):\n",
    "            course.append(li_tags[j].get_text())\n",
    "\n",
    "    taught.append(course)\n",
    "    \n",
    "        \n",
    "courses_file=open('courses_taught.txt','w',encoding='utf-8')\n",
    "for i in range (0,70):\n",
    "        courses_file.write(Titles[i]+\":\"+ str(taught[i]) +\"\\n\")        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
